a:98:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:0;}i:2;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:20:"cpp:Data exploration";i:1;s:17:" Data exploration";}i:2;i:1;}i:3;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:44;}i:4;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:44;}i:5;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:91:"Le fléau de la dimension est un problème qui complexifie inutilement un jeu de données. ";}i:2;i:46;}i:6;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:137;}i:7;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:137;}i:8;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:361:"L'ACP permet de réduire le nombre de dimensions d'un problème, en exprimant l'ensemble des données selon des axes, qui sont des combinaisons linéaires de toutes les autres variables. Ainsi chaque variable exprime un pourcentage de l'information totale ou variance totale (inertie), et l'objectif est de maximiser cette inertie pour gagner de l'information. ";}i:2;i:139;}i:9;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:500;}i:10;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:500;}i:11;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:1;i:1;s:10:"alert-info";}i:2;i:1;i:3;s:12:"<alert info>";}i:2;i:502;}i:12;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:1:" ";}i:2;i:3;i:3;s:1:" ";}i:2;i:514;}i:13;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:515;}i:14;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Remarque :";}i:2;i:517;}i:15;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:527;}i:16;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:78:" On utilisera le dataset de mesures de gaz contenus dans l'alcool, disponible ";}i:2;i:3;i:3;s:78:" On utilisera le dataset de mesures de gaz contenus dans l'alcool, disponible ";}i:2;i:529;}i:17;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:66:"https://archive.ics.uci.edu/ml/datasets/Alcohol+QCM+Sensor+Dataset";i:1;s:3:"ici";}i:2;i:607;}i:18;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:37:". On considérera le premier relevé.";}i:2;i:3;i:3;s:37:". On considérera le premier relevé.";}i:2;i:681;}i:19;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</alert>";}i:2;i:718;}i:20;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:726;}i:21;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:727;}i:22;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:729;}i:23;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:730;}i:24;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:732;}i:25;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:2;i:1;i:2;i:2;i:733;}i:2;i:732;}i:26;a:3:{i:0;s:15:"tablethead_open";i:1;a:0:{}i:2;i:732;}i:27;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:732;}i:28;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:732;}i:29;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"  Mauvais point de vue  ";}i:2;i:734;}i:30;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:758;}i:31;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:758;}i:32;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"  Bon point de vue  ";}i:2;i:759;}i:33;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:779;}i:34;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:780;}i:35;a:3:{i:0;s:16:"tablethead_close";i:1;a:0:{}i:2;i:780;}i:36;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:780;}i:37;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:780;}i:38;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:782;}i:39;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:17:":cpp:lamaface.jpg";i:1;s:0:"";i:2;N;i:3;s:3:"270";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:784;}i:40;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:810;}i:41;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:812;}i:42;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:812;}i:43;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:813;}i:44;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:19:":cpp:lamaprofil.jpg";i:1;s:0:"";i:2;N;i:3;s:3:"400";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:815;}i:45;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:843;}i:46;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:845;}i:47;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:846;}i:48;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:846;}i:2;i:846;}i:49;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:846;}i:50;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:848;}i:51;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:850;}i:52;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:851;}i:53;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:175:"
L'idée est de trouver le bon point de vue ou la variance du dataset sera maximisée. Ainsi, il y a un gain d'information et l'entrainement du modèle n'en sera que meilleur.";}i:2;i:853;}i:54;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1028;}i:55;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:37:"Construction du modèle de réduction";i:1;i:4;i:2;i:1030;}i:2;i:1030;}i:56;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:4;}i:2;i:1030;}i:57;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1030;}i:58;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:178:"On commence tout d'abord par regarder quelle part de l'information est expliquée par chaque variable et combien de variables il nous faut pour expliquer 95 % de l'information.";}i:2;i:1075;}i:59;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1253;}i:60;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1253;}i:61;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:1255;}i:62;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"Code Python";}i:2;i:1257;}i:63;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:1268;}i:64;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1270;}i:65;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:588:"
from sklearn.decomposition import PCA

model = PCA(n_components = 15)#Création du modèle de réduction sur toutes les variables du dataset
X_reduced = model.fit_transform(data)#Application de la réduction aux données d'entrainement
np.argmax(np.cumsum(model.explained_variance_ratio_)) > 0.95#Détermination des variables 

plt.figure(figsize=(12,6))#Définition de la taille du graphique
plt.plot(np.cumsum(model.explained_variance_ratio_))#Affichage des variances expliquées en fonction du nombre de variables

plt.xlabel("Nombres de variables")
plt.ylabel("Variance expliquée")
";i:1;s:6:"python";i:2;N;}i:2;i:1277;}i:66;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1277;}i:67;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:1882;}i:68;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"Code R";}i:2;i:1884;}i:69;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:1890;}i:70;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1892;}i:71;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:192:"
library(explor)
library(factoMineR)

res.PCA = PCA(scale(data))#Création du modèle de réduction
explor(res.PCA)#Ouverture d'une fenêtre permettant de visualiser les variables importantes
";i:1;s:6:"python";i:2;N;}i:2;i:1899;}i:72;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2108;}i:73;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:9:"Résultat";i:1;i:5;i:2;i:2108;}i:2;i:2108;}i:74;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:5;}i:2;i:2108;}i:75;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2108;}i:76;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:27:":cpp:variance_expliquee.png";i:1;s:73:"Variance expliquée en fonction du nombre de variables du jeu de données";i:2;s:6:"center";i:3;s:3:"600";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:2123;}i:77;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2234;}i:78;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:16:"divalign2_center";i:1;a:3:{i:0;s:6:"center";i:1;i:1;i:2;i:2236;}i:2;i:1;i:3;s:3:";#;";}i:2;i:2236;}i:79;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:2239;}i:80;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Figure 5 :";}i:2;i:2241;}i:81;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:2251;}i:82;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:74:" Variance expliquée en fonction du nombre de variables du jeu de données";}i:2;i:2253;}i:83;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:16:"divalign2_center";i:1;a:3:{i:0;s:6:"center";i:1;i:3;i:2;i:2253;}i:2;i:3;i:3;s:74:" Variance expliquée en fonction du nombre de variables du jeu de données";}i:2;i:2253;}i:84;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:16:"divalign2_center";i:1;a:3:{i:0;s:6:"center";i:1;i:4;i:2;i:2327;}i:2;i:4;i:3;s:4:"
;#;";}i:2;i:2327;}i:85;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2334;}i:86;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:6:"Source";i:1;i:5;i:2;i:2334;}i:2;i:2334;}i:87;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:5;}i:2;i:2334;}i:88;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:2345;}i:89;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2345;}i:90;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2345;}i:91;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:2349;}i:92;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:92:"https://www.youtube.com/watch?v=FTtzd31IAOw&list=PLO_fdPEVlfKqMDNmCFzQISI2H_nJcEDJq&index=28";i:1;s:43:" Machine Learnia par Guillaume Saint-Cirgue";}i:2;i:2350;}i:93;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2490;}i:94;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2490;}i:95;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2490;}i:96;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2490;}i:97;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:2490;}}