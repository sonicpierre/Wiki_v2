a:778:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:0;}i:2;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:6:"cpp:IA";i:1;s:17:" Machine Learning";}i:2;i:1;}i:3;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:29;}i:4;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:34:":cpp:imagecouvertureregression.png";i:1;s:0:"";i:2;N;i:3;s:3:"550";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:30;}i:5;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:73;}i:6;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:74;}i:7;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:76;}i:8;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:77;}i:9;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:147:"
Les différentes régressions sont le plus souvent utilisées pour prédire des cibles quantitatives (prix d'appartement, nombre de morts du COVID";}i:2;i:79;}i:10;a:3:{i:0;s:6:"entity";i:1;a:1:{i:0;s:3:"...";}i:2;i:226;}i:11;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:240:"). Il en existe beaucoup et nous allons ici décrire les principaux. Cette documentation résumera les parties théoriques pour laisser la place à la description du contexte d'utilisation et des forces et faiblesses de chacun des modèles.";}i:2;i:229;}i:12;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:469;}i:13;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:22:"Génération de points";i:1;i:2;i:2;i:471;}i:2;i:471;}i:14;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:471;}i:15;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:471;}i:16;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:175:"Pour commencer nous allons générer les points qui nous permettront d'entraîner les modèles. On rajoute un certain bruit modélisé grâce à l'aléatoire sur les données.";}i:2;i:505;}i:17;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:680;}i:18;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:680;}i:19;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:682;}i:20;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En python :";}i:2;i:684;}i:21;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:695;}i:22;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:697;}i:23;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:115:"
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100,1)
plt.figure(figsize=(10,8))
plt.scatter(X,y)
";i:1;s:6:"python";i:2;N;}i:2;i:704;}i:24;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:704;}i:25;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:836;}i:26;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:838;}i:27;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:844;}i:28;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:846;}i:29;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:65:"
X = 2 * rnorm(100,1,1)
y = 4 + 3 * X + rnorm(100,1,1)
plot(X,y)
";i:1;s:6:"python";i:2;N;}i:2;i:853;}i:30;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:853;}i:31;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:935;}i:32;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:9:"Résultat";}i:2;i:937;}i:33;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:946;}i:34;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:948;}i:35;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:948;}i:36;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:29:":cpp:regressiontestpython.png";i:1;s:0:"";i:2;s:6:"center";i:3;s:3:"400";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:950;}i:37;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:990;}i:38;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:991;}i:39;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:991;}i:40;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:27:"Les régressions linéaires";i:1;i:2;i:2;i:991;}i:2;i:991;}i:41;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:991;}i:42;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1030;}i:43;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:10:"Théorie :";i:1;i:3;i:2;i:1030;}i:2;i:1030;}i:44;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:1030;}i:45;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1030;}i:46;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:45:"Les régressions linéaires sont de la forme ";}i:2;i:1050;}i:47;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1095;}i:48;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:41:"y = a * x_{0} + b * x_{1} + c * x_{2} + d";i:2;i:3;i:3;s:41:"y = a * x_{0} + b * x_{1} + c * x_{2} + d";}i:2;i:1096;}i:49;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1137;}i:50;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:33:" où y est la variable prédite, ";}i:2;i:1138;}i:51;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1171;}i:52;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:21:"(x_{0}, x_{1}, x_{2})";i:2;i:3;i:3;s:21:"(x_{0}, x_{1}, x_{2})";}i:2;i:1172;}i:53;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1193;}i:54;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:38:" sont les variables d'entrainement et ";}i:2;i:1194;}i:55;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1232;}i:56;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:12:"(a, b, c, d)";i:2;i:3;i:3;s:12:"(a, b, c, d)";}i:2;i:1233;}i:57;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1245;}i:58;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:54:" sont les pondérations enfin d est le terme constant.";}i:2;i:1246;}i:59;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1300;}i:60;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1300;}i:61;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:37:"On peut résumer cette équation à :";}i:2;i:1302;}i:62;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1339;}i:63;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1339;}i:64;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:2:"$$";i:2;i:1;i:3;s:2:"$$";}i:2;i:1341;}i:65;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:32:"ŷ = h_{\theta}(x) = \theta . x$";i:2;i:3;i:3;s:32:"ŷ = h_{\theta}(x) = \theta . x$";}i:2;i:1343;}i:66;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1375;}i:67;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:1376;}i:68;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1377;}i:69;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:1377;}i:70;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1377;}i:71;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1377;}i:72;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1381;}i:73;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1382;}i:74;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:6:"\theta";i:2;i:3;i:3;s:6:"\theta";}i:2;i:1383;}i:75;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1389;}i:76;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:38:" est le vecteur paramètre du modèle ";}i:2;i:1390;}i:77;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1428;}i:78;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:14:"(a,b,c,\ldots)";i:2;i:3;i:3;s:11:"(a,b,c,...)";}i:2;i:1429;}i:79;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1440;}i:80;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1441;}i:81;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1441;}i:82;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1441;}i:83;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1441;}i:84;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1445;}i:85;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1446;}i:86;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"x";i:2;i:3;i:3;s:1:"x";}i:2;i:1447;}i:87;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1448;}i:88;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:33:" sont les valeurs d'entrainement ";}i:2;i:1449;}i:89;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1482;}i:90;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:28:"(x_{0}, x_{1}, x_{2},\ldots)";i:2;i:3;i:3;s:25:"(x_{0}, x_{1}, x_{2},...)";}i:2;i:1483;}i:91;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1508;}i:92;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1509;}i:93;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1509;}i:94;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1509;}i:95;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1509;}i:96;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:53:"Le produit scalaire entre les deux nous donnera donc ";}i:2;i:1511;}i:97;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1564;}i:98;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1564;}i:99;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:2:"$$";i:2;i:1;i:3;s:2:"$$";}i:2;i:1566;}i:100;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:35:"a*x_{0} + b*x_{1} + c*x_{2} \ldots$";i:2;i:3;i:3;s:32:"a*x_{0} + b*x_{1} + c*x_{2} ...$";}i:2;i:1568;}i:101;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1600;}i:102;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1601;}i:103;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1601;}i:104;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:29:"On en déduit que forcément ";}i:2;i:1603;}i:105;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1632;}i:106;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:3:"a=1";i:2;i:3;i:3;s:3:"a=1";}i:2;i:1633;}i:107;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1636;}i:108;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:".
";}i:2;i:1637;}i:109;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:1639;}i:110;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:1641;}i:111;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:1642;}i:112;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:1644;}i:113;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:1645;}i:114;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:16:"Erreur associée";}i:2;i:1647;}i:115;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:1663;}i:116;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:1665;}i:117;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:1666;}i:118;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:1668;}i:119;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:1669;}i:120;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:166:"
La MSE (Mean Square Error) est la plus simple à minimiser et implique que la RMSE (Root Mean Square Error) sera minimisée. Rappelons la forme qui la caractérise :";}i:2;i:1671;}i:121;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1837;}i:122;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:1837;}i:123;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:2:"$$";i:2;i:1;i:3;s:2:"$$";}i:2;i:1839;}i:124;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:102:"MSE(X,h_{\theta}) = \frac{1}{m} \overset{m}{\underset{i = 1}{\sum}} ( \theta~^T x^{(i)} - y^{(i)})^2 $";i:2;i:3;i:3;s:102:"MSE(X,h_{\theta}) = \frac{1}{m} \overset{m}{\underset{i = 1}{\sum}} ( \theta~^T x^{(i)} - y^{(i)})^2 $";}i:2;i:1841;}i:125;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1943;}i:126;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:1944;}i:127;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:1945;}i:128;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:1947;}i:129;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:1947;}i:130;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1947;}i:131;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1947;}i:132;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1951;}i:133;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1952;}i:134;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"y";i:2;i:3;i:3;s:1:"y";}i:2;i:1953;}i:135;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1954;}i:136;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:" sont les valeurs cibles";}i:2;i:1955;}i:137;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1979;}i:138;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1979;}i:139;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1979;}i:140;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1979;}i:141;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1983;}i:142;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:1984;}i:143;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"m";i:2;i:3;i:3;s:1:"m";}i:2;i:1985;}i:144;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:1986;}i:145;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:" le nombre de valeurs d'entrainement";}i:2;i:1987;}i:146;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2023;}i:147;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2023;}i:148;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:2023;}i:149;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2025;}i:150;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:36:"Méthode analytique (mathématiques)";i:1;i:3;i:2;i:2025;}i:2;i:2025;}i:151;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:2025;}i:152;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2025;}i:153;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:102:"Une des méthodes pour obtenir les meilleurs coefficients le plus rapidement est l'équation normale :";}i:2;i:2071;}i:154;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2173;}i:155;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2173;}i:156;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:2:"$$";i:2;i:1;i:3;s:2:"$$";}i:2;i:2175;}i:157;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:30:"\theta = (X~^tX)^{-1} X~^t y $";i:2;i:3;i:3;s:30:"\theta = (X~^tX)^{-1} X~^t y $";}i:2;i:2177;}i:158;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:2207;}i:159;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2208;}i:160;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2208;}i:161;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:2210;}i:162;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Pratique :";}i:2;i:2212;}i:163;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:2222;}i:164;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2224;}i:165;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2224;}i:166;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:2226;}i:167;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:2228;}i:168;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:2239;}i:169;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2241;}i:170;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:266:"
X_b = np.c_[np.ones((100,1)), X] # ajouter x0 = 1 à chaque observation voir partie théorique
theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y) #.dot permet la multiplication entre matrices et .linalg.inv permet d'inverser la matrice 
print(theta_best)
";i:1;s:6:"python";i:2;N;}i:2;i:2248;}i:171;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2248;}i:172;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:2531;}i:173;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:2533;}i:174;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:2539;}i:175;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2541;}i:176;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:267:"
vecteurUnitaire <- rep(1,100)
X_b = matrix(c(vecteurUnitaire, X), nrow = 100, ncol = 2)
theta_best <- solve(aperm(X_b) %*% X_b) %*% aperm(X_b) %*% y #%*% permet de faire une multiplication entre 2 matrices, aperm permet de calculer une transposée
print(theta_best)
";i:1;s:6:"python";i:2;N;}i:2;i:2548;}i:177;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2548;}i:178;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:2832;}i:179;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"Résultat :";}i:2;i:2834;}i:180;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:2845;}i:181;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2847;}i:182;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2847;}i:183;a:3:{i:0;s:11:"unformatted";i:1;a:1:{i:0;s:40:"
array([[4.215087],
      [2.7701154]])
";}i:2;i:2857;}i:184;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2906;}i:185;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2906;}i:186;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:130:"Si la méthode était parfaite on aurait trouvé a=4 et b=3, le bruit dans le jeu de données n’a pas donné cette possibilité.";}i:2;i:2908;}i:187;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3038;}i:188;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:3040;}i:189;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:33:"Méthode utilisant les librairies";i:1;i:3;i:2;i:3040;}i:2;i:3040;}i:190;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:3040;}i:191;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3040;}i:192;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:114:"Cette méthode est prés codé et utilise la méthode des moindres carrés avec la fonction scipy.linalg.ltsq().  ";}i:2;i:3083;}i:193;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3197;}i:194;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3197;}i:195;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:3199;}i:196;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:3201;}i:197;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:3212;}i:198;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3214;}i:199;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:203:"
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X,y)
print(lin_reg.intercept_) #Il s'agit du terme constant
print(lin_reg.coef_)  #Il s'agit des pondérations
";i:1;s:6:"python";i:2;N;}i:2;i:3221;}i:200;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3221;}i:201;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:3441;}i:202;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:3443;}i:203;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:3449;}i:204;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3451;}i:205;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:36:"
model = lm(X~y)
print(coef(model))
";i:1;s:6:"python";i:2;N;}i:2;i:3458;}i:206;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3458;}i:207;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:3511;}i:208;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"Résultat :";}i:2;i:3513;}i:209;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:3524;}i:210;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3526;}i:211;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3526;}i:212;a:3:{i:0;s:11:"unformatted";i:1;a:1:{i:0;s:17:"
[4.21]
[[9.75]]
";}i:2;i:3536;}i:213;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3562;}i:214;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3562;}i:215;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:71:"Maintenant qu'on a un modèle il est intéressant de vous sa valeur MSE";}i:2;i:3564;}i:216;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3635;}i:217;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3635;}i:218;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:3637;}i:219;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En python :";}i:2;i:3639;}i:220;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:3650;}i:221;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3652;}i:222;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:127:"
from sklearn.metrics import mean_squared_error
ypred = lin_reg.intercept_ + lin_reg.coef_[0] * X
mean_squared_error(y, ypred)
";i:1;s:6:"python";i:2;N;}i:2;i:3659;}i:223;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3659;}i:224;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:3803;}i:225;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:3805;}i:226;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:3811;}i:227;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3813;}i:228;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:59:"
lm_mse <- mean((y - model$fitted.values)^2)
print(lm_mse)
";i:1;s:6:"python";i:2;N;}i:2;i:3820;}i:229;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3820;}i:230;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:3896;}i:231;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"Résultat :";}i:2;i:3898;}i:232;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:3909;}i:233;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3911;}i:234;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3911;}i:235;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:18:"0.7728972383696089";}i:2;i:3913;}i:236;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:3931;}i:237;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:3931;}i:238;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:88:"Visualisons les résultats dans un graphique adapté pour être sûr de ses résultats :";}i:2;i:3933;}i:239;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4021;}i:240;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4021;}i:241;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:4023;}i:242;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:4025;}i:243;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:4036;}i:244;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4038;}i:245;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:143:"
plt.figure(figsize=(10,8))
plt.scatter(X,y)
x = np.linspace(0, 2, 1000)
yConstruit = theta_best[0] * x + theta_best[1]
plt.plot(x,yConstruit)
";i:1;s:6:"python";i:2;N;}i:2;i:4045;}i:246;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4045;}i:247;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:4205;}i:248;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:4207;}i:249;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:4213;}i:250;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4215;}i:251;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:122:"
library(pracma)
plot(X,y)
x = linspace(-3,30,1500)
yConstruit = coef(model)[1] + coef(model)[2] * x
lines(yConstruit, x)
";i:1;s:6:"python";i:2;N;}i:2;i:4222;}i:252;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4222;}i:253;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:22:":cpp:resregression.png";i:1;s:0:"";i:2;s:6:"center";i:3;s:3:"400";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:4361;}i:254;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4394;}i:255;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4396;}i:256;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:13:"Utilisation :";i:1;i:3;i:2;i:4396;}i:2;i:4396;}i:257;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:4396;}i:258;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:4;i:1;i:2;i:2;i:4419;}i:2;i:4418;}i:259;a:3:{i:0;s:15:"tablethead_open";i:1;a:0:{}i:2;i:4418;}i:260;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:4418;}i:261;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:4418;}i:262;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4420;}i:263;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:4421;}i:264;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:4421;}i:265;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:31:" Gérer beaucoup de donnée    ";}i:2;i:4422;}i:266;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:4453;}i:267;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:4453;}i:268;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:16:" Complexité    ";}i:2;i:4454;}i:269;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:4470;}i:270;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:4470;}i:271;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:" Evaluer la précision";}i:2;i:4471;}i:272;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:4493;}i:273;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:4494;}i:274;a:3:{i:0;s:16:"tablethead_close";i:1;a:0:{}i:2;i:4494;}i:275;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:4494;}i:276;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:4494;}i:277;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:30:" Régression linéaire ​    ";}i:2;i:4496;}i:278;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:4526;}i:279;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:4526;}i:280;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:72:"Ce modèle est optimal quand il n’y a pas trop de variables (<100 000)";}i:2;i:4527;}i:281;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:4599;}i:282;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:4599;}i:283;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:" Linéaire ";}i:2;i:4600;}i:284;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:4611;}i:285;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:7:"O(n^{2}";i:2;i:3;i:3;s:7:"O(n^{2}";}i:2;i:4612;}i:286;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:4619;}i:287;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:63:"), sinon l'inversion de la matrice est trop coûteuse.         ";}i:2;i:4620;}i:288;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:4683;}i:289;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:4683;}i:290;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:" Métrique adapté RMSE	";}i:2;i:4684;}i:291;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:4708;}i:292;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:4709;}i:293;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:4709;}i:2;i:4709;}i:294;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4709;}i:295;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4711;}i:296;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"Source :";}i:2;i:4713;}i:297;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4721;}i:298;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4723;}i:299;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:4723;}i:300;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4723;}i:301;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4723;}i:302;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4727;}i:303;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:107:"https://openclassrooms.com/fr/courses/1393696-effectuez-vos-etudes-statistiques-avec-r/1394666-les-matrices";i:1;N;}i:2;i:4728;}i:304;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4839;}i:305;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4839;}i:306;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4839;}i:307;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4839;}i:308;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:4843;}i:309;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:68:"https://fr.wikibooks.org/wiki/Programmer_en_R/Manipuler_les_matrices";i:1;N;}i:2;i:4844;}i:310;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4916;}i:311;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4916;}i:312;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:4916;}i:313;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:4917;}i:314;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:25:"Les descentes de gradient";i:1;i:2;i:2;i:4917;}i:2;i:4917;}i:315;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:4917;}i:316;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4917;}i:317;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:1;i:1;s:13:"alert-warning";}i:2;i:1;i:3;s:15:"<alert warning>";}i:2;i:4954;}i:318;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:4969;}i:319;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:12:"Indication :";}i:2;i:4971;}i:320;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:4983;}i:321;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:102:"  Il est important de normaliser les données avant d'appliquer un algorithme de descente de gradient.";}i:2;i:3;i:3;s:102:"  Il est important de normaliser les données avant d'appliquer un algorithme de descente de gradient.";}i:2;i:4985;}i:322;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</alert>";}i:2;i:5087;}i:323;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5095;}i:324;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5095;}i:325;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:206:"Nous allons ici développer la descente de gradient dans le cas d'une régression linéaire mais il est important de savoir que cette méthode est une des plus utilisées dans les problèmes d'optimisation.";}i:2;i:5097;}i:326;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5304;}i:327;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:5304;}i:328;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:36:"Les descentes de gradient classiques";i:1;i:3;i:2;i:5304;}i:2;i:5304;}i:329;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:5304;}i:330;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5304;}i:331;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:68:"Commençons par introduire le problème de la descente de gradient :";}i:2;i:5350;}i:332;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5418;}i:333;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"imagebox";i:1;a:2:{i:0;i:1;i:1;a:10:{s:4:"type";s:13:"internalmedia";s:3:"src";s:27:":cpp:descentedegradient.png";s:5:"title";s:0:"";s:5:"align";s:6:"center";s:5:"width";s:3:"950";s:6:"height";d:526;s:5:"cache";s:5:"cache";s:7:"linking";s:7:"details";s:6:"detail";s:87:"/lib/exe/detail.php?id=cpp%3Aregression_supervisee&amp;media=cpp:descentedegradient.png";s:5:"exist";b:1;}}i:2;i:1;i:3;s:37:"[{{ :cpp:descentedegradient.png?950 |";}i:2;i:5420;}i:334;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"imagebox";i:1;a:2:{i:0;i:3;i:1;s:35:" Schéma d'une descente de gradient";}i:2;i:3;i:3;s:35:" Schéma d'une descente de gradient";}i:2;i:5457;}i:335;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"imagebox";i:1;a:2:{i:0;i:4;i:1;s:3:"}}]";}i:2;i:4;i:3;s:3:"}}]";}i:2;i:5492;}i:336;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5492;}i:337;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:1;i:1;s:13:"alert-warning";}i:2;i:1;i:3;s:15:"<alert warning>";}i:2;i:5497;}i:338;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:5512;}i:339;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Remarque :";}i:2;i:5514;}i:340;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:5524;}i:341;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:136:" La fonction MSE représentative de l'erreur est convexe, il y a donc pas de minimums locaux (petits creux avant le fond de la vallée).";}i:2;i:3;i:3;s:136:" La fonction MSE représentative de l'erreur est convexe, il y a donc pas de minimums locaux (petits creux avant le fond de la vallée).";}i:2;i:5526;}i:342;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</alert>";}i:2;i:5662;}i:343;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5670;}i:344;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5670;}i:345;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:5672;}i:346;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:5674;}i:347;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:5675;}i:348;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Théorie :";}i:2;i:5677;}i:349;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:5687;}i:350;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5689;}i:351;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5689;}i:352;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:268:"Il faut voir la complexité comme une fonction dont on cherche le minimum (la vallée). On fait varier les paramètres pour essayer d'avoir un minimum d'erreur. Pour cela, on calcule les dérivées partielles de cette fonction par rapport aux différents paramètres :";}i:2;i:5691;}i:353;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:5959;}i:354;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:5959;}i:355;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:2:"$$";i:2;i:1;i:3;s:2:"$$";}i:2;i:5961;}i:356;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:302:"\nabla_{\theta}MSE(\theta) = \begin{pmatrix}
\frac{\partial }{\partial \theta_{0}} MSE(\theta)\\[4mm]
\frac{\partial }{\partial \theta_{1}} MSE(\theta)\\[0.1mm]
.\\[0.1mm]
.\\[0.1mm]
.\\[0.1mm]
\frac{\partial }{\partial \theta_{n}} MSE(\theta)\\[0.1mm]
\end{pmatrix}  = \frac{2}{m} + X~^t(X\theta - y)$";i:2;i:3;i:3;s:302:"\nabla_{\theta}MSE(\theta) = \begin{pmatrix}
\frac{\partial }{\partial \theta_{0}} MSE(\theta)\\[4mm]
\frac{\partial }{\partial \theta_{1}} MSE(\theta)\\[0.1mm]
.\\[0.1mm]
.\\[0.1mm]
.\\[0.1mm]
\frac{\partial }{\partial \theta_{n}} MSE(\theta)\\[0.1mm]
\end{pmatrix}  = \frac{2}{m} + X~^t(X\theta - y)$";}i:2;i:5963;}i:357;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6265;}i:358;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:6266;}i:359;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6267;}i:360;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:2;i:1;i:6;i:2;i:6268;}i:2;i:6267;}i:361;a:3:{i:0;s:15:"tablethead_open";i:1;a:0:{}i:2;i:6267;}i:362;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6267;}i:363;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6267;}i:364;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:"  Paramètre  ";}i:2;i:6269;}i:365;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:6283;}i:366;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6283;}i:367;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"  Signification  ";}i:2;i:6284;}i:368;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:6301;}i:369;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6302;}i:370;a:3:{i:0;s:16:"tablethead_close";i:1;a:0:{}i:2;i:6302;}i:371;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6302;}i:372;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6302;}i:373;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6304;}i:374;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:6306;}i:375;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:26:"\nabla_{\theta}MSE(\theta)";i:2;i:3;i:3;s:26:"\nabla_{\theta}MSE(\theta)";}i:2;i:6307;}i:376;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6333;}i:377;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6334;}i:378;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6336;}i:379;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6336;}i:380;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:47:"  Dérivée partielle de la fonction d'erreur  ";}i:2;i:6337;}i:381;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6384;}i:382;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6385;}i:383;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6385;}i:384;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6385;}i:385;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6387;}i:386;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:6389;}i:387;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"X";i:2;i:3;i:3;s:1:"X";}i:2;i:6390;}i:388;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6391;}i:389;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6392;}i:390;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6394;}i:391;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6394;}i:392;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:"  Ensemble du jeu d'entrainement  ";}i:2;i:6395;}i:393;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6429;}i:394;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6430;}i:395;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6430;}i:396;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6430;}i:397;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6432;}i:398;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:6434;}i:399;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:6:"\theta";i:2;i:3;i:3;s:6:"\theta";}i:2;i:6435;}i:400;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6441;}i:401;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6442;}i:402;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6444;}i:403;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6444;}i:404;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:41:"  Paramètre de la fonction prédictive  ";}i:2;i:6445;}i:405;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6486;}i:406;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6487;}i:407;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6487;}i:408;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6487;}i:409;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6489;}i:410;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:6491;}i:411;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"y";i:2;i:3;i:3;s:1:"y";}i:2;i:6492;}i:412;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6493;}i:413;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6494;}i:414;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6496;}i:415;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6496;}i:416;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:28:"  Réponse aux estimations  ";}i:2;i:6497;}i:417;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6525;}i:418;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6526;}i:419;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6526;}i:420;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6526;}i:421;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6528;}i:422;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:6530;}i:423;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"m";i:2;i:3;i:3;s:1:"m";}i:2;i:6531;}i:424;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6532;}i:425;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:2:"  ";}i:2;i:6533;}i:426;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6535;}i:427;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6535;}i:428;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:26:"  Nombre d'échantillons  ";}i:2;i:6536;}i:429;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6562;}i:430;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6563;}i:431;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:6563;}i:2;i:6563;}i:432;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6563;}i:433;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:131:"On peut définir maintenant la suite qui va permettre d'adapter les différents paramètres en réduisant à chaque fois l'erreur.
";}i:2;i:6565;}i:434;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:6696;}i:435;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:6698;}i:436;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:2:"$$";i:2;i:1;i:3;s:2:"$$";}i:2;i:6699;}i:437;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:67:" \theta_{n+1} = \theta_{n} - \eta * \nabla_{\theta}MSE(\theta_{n})$";i:2;i:3;i:3;s:67:" \theta_{n+1} = \theta_{n} - \eta * \nabla_{\theta}MSE(\theta_{n})$";}i:2;i:6701;}i:438;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6768;}i:439;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:6769;}i:440;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:6770;}i:441;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6772;}i:442;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:2;i:1;i:2;i:2;i:6773;}i:2;i:6772;}i:443;a:3:{i:0;s:15:"tablethead_open";i:1;a:0:{}i:2;i:6772;}i:444;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6772;}i:445;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:6772;}i:446;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"      Paramètre        ";}i:2;i:6774;}i:447;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:6798;}i:448;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:6798;}i:449;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:" Signification";}i:2;i:6799;}i:450;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:6813;}i:451;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6814;}i:452;a:3:{i:0;s:16:"tablethead_close";i:1;a:0:{}i:2;i:6814;}i:453;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:6814;}i:454;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:6814;}i:455;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:6816;}i:456;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:1;i:3;s:1:"$";}i:2;i:6817;}i:457;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:4:"\eta";i:2;i:3;i:3;s:4:"\eta";}i:2;i:6818;}i:458;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:18:"mathjax_protecttex";i:1;s:1:"$";i:2;i:4;i:3;s:1:"$";}i:2;i:6822;}i:459;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:6823;}i:460;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6824;}i:461;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:6824;}i:462;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:55:" La distance du pas du Monsieur (taux d'apprentissage) ";}i:2;i:6825;}i:463;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:6880;}i:464;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:6881;}i:465;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:6881;}i:2;i:6881;}i:466;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6881;}i:467;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:6883;}i:468;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:26:"Pratique sans librairies :";}i:2;i:6885;}i:469;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:6911;}i:470;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:6913;}i:471;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:6913;}i:472;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:225:"Maintenant, nous allons mettre en place cet algorithme d'un point de vue technique dans le code. Pour démarrer on fixe les constantes importantes et nécessaires à l'algorithme et on fixe le point de départ aléatoirement.";}i:2;i:6915;}i:473;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7140;}i:474;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7140;}i:475;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:7142;}i:476;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:7144;}i:477;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:7155;}i:478;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7157;}i:479;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:273:"
eta = 0.1 #Taux d'apprentissage (pas du Monsieur)
n_iterations = 1000 #Nombre d'itérations de l'algorithme
m = 100 #Nombre d'échantillons
theta = np.random.randn(2,1) #Paramètre fixé aléatoirement
X_b = np.c_[np.ones((100,1)), X] #ajoute x0 = 1 à chaque observation
";i:1;s:6:"python";i:2;N;}i:2;i:7164;}i:480;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7164;}i:481;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:7454;}i:482;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:7456;}i:483;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:7462;}i:484;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7464;}i:485;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:117:"
eta <- 0.1
n_iteration <- 100
m <- 100
theta <- rnorm(2)
X_b <- matrix(c(vecteurUnitaire, X), nrow = 100, ncol = 2)
";i:1;s:6:"python";i:2;N;}i:2;i:7471;}i:486;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7471;}i:487;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:118:"Maintenant que nous avons défini les constantes nécessaires, il est possible de traduire les formules correctement :";}i:2;i:7605;}i:488;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7723;}i:489;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7723;}i:490;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:7725;}i:491;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:7727;}i:492;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:7738;}i:493;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7740;}i:494;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:125:"
for iteration in range(n_iterations):
    gradients = 2/m * X_b.T.dot(X_b.dot(theta)-y)
    theta = theta - eta * gradients
";i:1;s:6:"python";i:2;N;}i:2;i:7747;}i:495;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7747;}i:496;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:7889;}i:497;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:7891;}i:498;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:7897;}i:499;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7899;}i:500;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:124:"
for(i in 0:n_iteration){
    gradient <- 2/m * aperm(X_b) %*% ((X_b %*% theta) - y)
    theta <- theta - eta * gradient 
}
";i:1;s:6:"python";i:2;N;}i:2;i:7906;}i:501;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7906;}i:502;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:1;i:1;s:13:"alert-warning";}i:2;i:1;i:3;s:15:"<alert warning>";}i:2;i:8047;}i:503;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:8062;}i:504;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Remarque :";}i:2;i:8064;}i:505;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:8074;}i:506;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:101:" Il est parfois plus judicieux de fixer une erreur minimale plutôt qu'un nombre d'itération maximal";}i:2;i:3;i:3;s:101:" Il est parfois plus judicieux de fixer une erreur minimale plutôt qu'un nombre d'itération maximal";}i:2;i:8076;}i:507;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</alert>";}i:2;i:8177;}i:508;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8185;}i:509;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8185;}i:510;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:8187;}i:511;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"Résultat :";}i:2;i:8189;}i:512;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:8200;}i:513;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8202;}i:514;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8202;}i:515;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:30:":cpp:descentegradientpetit.png";i:1;s:28:" Mr fait des pas trop petits";i:2;s:6:"center";i:3;s:3:"400";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:8204;}i:516;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:8273;}i:517;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:34:":cpp:descentegradienttropgrand.png";i:1;s:28:" Mr fait des pas trop grands";i:2;s:4:"left";i:3;s:3:"400";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:8274;}i:518;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8346;}i:519;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8346;}i:520;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:27:":cpp:descentegradientok.png";i:1;s:31:" Mr fait la bonne taille de pas";i:2;s:4:"left";i:3;s:3:"400";i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:8348;}i:521;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8416;}i:522;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8416;}i:523;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8418;}i:524;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8420;}i:525;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8421;}i:526;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8423;}i:527;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8424;}i:528;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8426;}i:529;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8427;}i:530;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8429;}i:531;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8430;}i:532;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8432;}i:533;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8433;}i:534;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8435;}i:535;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8436;}i:536;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8438;}i:537;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8439;}i:538;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8441;}i:539;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8442;}i:540;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8444;}i:541;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8445;}i:542;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8447;}i:543;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8448;}i:544;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8450;}i:545;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8451;}i:546;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8453;}i:547;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:8454;}i:548;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:"
";}i:2;i:8456;}i:549;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:8457;}i:550;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:30:"Pratique avec les librairies :";}i:2;i:8459;}i:551;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:8489;}i:552;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8491;}i:553;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8491;}i:554;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:96:"Il est aussi possible de faire une descente de gradient dans ce cas en utilisant les librairies ";}i:2;i:8493;}i:555;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8589;}i:556;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8589;}i:557;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:8591;}i:558;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:8593;}i:559;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:8604;}i:560;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8606;}i:561;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:125:"
from sklearn.linear_model import SGDRegressor
model1 = SGDRegressor()
model1.fit(X,y.ravel())
model1.intercept_
model.coef_
";i:1;s:6:"python";i:2;N;}i:2;i:8613;}i:562;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8613;}i:563;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:8755;}i:564;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:8757;}i:565;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:8763;}i:566;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:8765;}i:567;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:134:"
library(gradDescent)
model1 <- gradDescentR.learn(Dtoy, featureScaling = FALSE, learningMethod = "GD", seed = 1)
print(model1$model)
";i:1;s:6:"python";i:2;N;}i:2;i:8772;}i:568;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8772;}i:569;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:1;i:1;s:12:"alert-danger";}i:2;i:1;i:3;s:14:"<alert danger>";}i:2;i:8923;}i:570;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:8937;}i:571;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"Danger :";}i:2;i:8939;}i:572;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:8947;}i:573;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:130:" L'ensemble des données est utilisé à chaque fois ce qui est un véritable problème car le programme en est fortement ralenti.";}i:2;i:3;i:3;s:130:" L'ensemble des données est utilisé à chaque fois ce qui est un véritable problème car le programme en est fortement ralenti.";}i:2;i:8949;}i:574;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</alert>";}i:2;i:9079;}i:575;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:9087;}i:576;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9088;}i:577;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:9088;}i:578;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:39:"Les descentes de gradient stochastiques";i:1;i:3;i:2;i:9088;}i:2;i:9088;}i:579;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:3;}i:2;i:9088;}i:580;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9088;}i:581;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:172:"Pour essayer de contrer la perte de temps dû au fait d'appliquer les calculs sur toutes les données à chaque itération la descente de gradient stochastique est apparue.";}i:2;i:9137;}i:582;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9309;}i:583;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9309;}i:584;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:9311;}i:585;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"Théorie";}i:2;i:9313;}i:586;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:9321;}i:587;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9323;}i:588;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9323;}i:589;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:148:"On va comparer et calculer le gradient en prenant une seule observation à chaque fois. Il y a différents avantages et des inconvénients à cela :";}i:2;i:9325;}i:590;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9473;}i:591;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:9473;}i:592;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:9473;}i:593;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:9473;}i:594;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:9477;}i:595;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:1;i:1;a:2:{i:0;s:14:"color:#22b14c;";i:1;s:0:"";}}i:2;i:1;i:3;s:15:"<color #22b14c>";}i:2;i:9478;}i:596;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:3;i:1;s:171:"Ceci accélère considérablement le programme mais va rendre la descente beaucoup plus irrégulière, votre bonhomme va monter puis redescendre mais en moyenne descendra.";}i:2;i:3;i:3;s:171:"Ceci accélère considérablement le programme mais va rendre la descente beaucoup plus irrégulière, votre bonhomme va monter puis redescendre mais en moyenne descendra.";}i:2;i:9493;}i:597;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</color>";}i:2;i:9664;}i:598;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:9672;}i:599;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:9672;}i:600;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:9672;}i:601;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:9672;}i:602;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:9676;}i:603;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:1;i:1;a:2:{i:0;s:14:"color:#22b14c;";i:1;s:0:"";}}i:2;i:1;i:3;s:15:"<color #22b14c>";}i:2;i:9677;}i:604;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:3;i:1;s:108:"Cette méthode est une façon d'éviter les minimums locaux si la fonction représentative de l'erreur en a.";}i:2;i:3;i:3;s:108:"Cette méthode est une façon d'éviter les minimums locaux si la fonction représentative de l'erreur en a.";}i:2;i:9692;}i:605;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</color>";}i:2;i:9800;}i:606;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:9808;}i:607;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:9808;}i:608;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:9808;}i:609;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:9808;}i:610;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:1;i:1;a:2:{i:0;s:14:"color:#ed1c24;";i:1;s:0:"";}}i:2;i:1;i:3;s:15:"<color #ed1c24>";}i:2;i:9812;}i:611;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:3;i:1;s:50:" L'algorithme n'atteindra jamais le minimum exact.";}i:2;i:3;i:3;s:50:" L'algorithme n'atteindra jamais le minimum exact.";}i:2;i:9827;}i:612;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</color>";}i:2;i:9877;}i:613;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:9885;}i:614;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:9885;}i:615;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:9885;}i:616;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:9885;}i:617;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:1;i:1;s:10:"alert-info";}i:2;i:1;i:3;s:12:"<alert info>";}i:2;i:9887;}i:618;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:9899;}i:619;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"Info :";}i:2;i:9901;}i:620;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:9907;}i:621;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:3;i:1;s:166:" Un autre bon moyen de mettre d'éviter les minimums locaux est de faire varier le pas durant la marche. On met un grand pas au départ et on réduit petit à petit. ";}i:2;i:3;i:3;s:166:" Un autre bon moyen de mettre d'éviter les minimums locaux est de faire varier le pas durant la marche. On met un grand pas au départ et on réduit petit à petit. ";}i:2;i:9909;}i:622;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:8:"alertbox";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</alert>";}i:2;i:10075;}i:623;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10083;}i:624;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10083;}i:625;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:10085;}i:626;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"Pratique";}i:2;i:10087;}i:627;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:10095;}i:628;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10097;}i:629;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10097;}i:630;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:70:"Mettons en place cet algorithme à l'aide des librairies disponibles :";}i:2;i:10099;}i:631;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10169;}i:632;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10169;}i:633;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:10171;}i:634;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"En Python :";}i:2;i:10173;}i:635;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:10184;}i:636;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10186;}i:637;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:478:"
from sklearn.linear_model import SGDRegressor
#eta est le taux d'apprentissage
#tol est la précision visée
#penalty permet de savoir si on effectue des opérations de régularisation ( prochaine page)
sgd_reg = SGDRegressor(max_iter = 1000, tol=1e-3, penalty=None, eta=0.1)
sgd_reg.fit(X, y.ravel()) #ravel permet de tout mettre dans une liste à une dimension
print(sgd_reg.intercept_) #affiche le coefficient constant
print(sgd_reg.coef_) #affiche les autres coefficients 
";i:1;s:6:"python";i:2;N;}i:2;i:10193;}i:638;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10193;}i:639;a:3:{i:0;s:14:"underline_open";i:1;a:0:{}i:2;i:10688;}i:640;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:6:"En R :";}i:2;i:10690;}i:641;a:3:{i:0;s:15:"underline_close";i:1;a:0:{}i:2;i:10696;}i:642;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10698;}i:643;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10698;}i:644;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:120:"Avant d'entraîner le modèle R va prendre l'ensemble des données, il faudra que la variable cible se trouve à la fin ";}i:2;i:10700;}i:645;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10820;}i:646;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:79:"
library(gradDescent)
donneeTotales <- matrix(c(X_b, y), nrow = 100, ncol = 2)
";i:1;s:6:"python";i:2;N;}i:2;i:10827;}i:647;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10827;}i:648;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:40:"On peut maintenant entraîner le modèle";}i:2;i:10923;}i:649;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10963;}i:650;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:579:"
#Feature Scaling permet de recalibrer les variables quand elles ne sont pas à la même échelle
#seed fixe la valeur de départ
sgd_reg <- gradDescentR.learn(donneeTotales, featureScaling = FALSE, learningMethod = "SGD", seed = 1)
#Remarque importante par desfaut le taux d'apprentissage est à 0.1 et le nombre maximum d'itération est de 10 
#ce qui est loi d'être optimal dans certains cas.
# Proposons une alternative :
sgd_reg <- gradDescentR.learn(donneeTotales, featureScaling = FALSE, learningMethod = "SGD", seed = 1, control = list(maxIter = 100))
print(mgd2$model)
";i:1;s:6:"python";i:2;N;}i:2;i:10970;}i:651;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10970;}i:652;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:1;i:1;a:2:{i:0;s:14:"color:#22b14c;";i:1;s:0:"";}}i:2;i:1;i:3;s:15:"<color #22b14c>";}i:2;i:11566;}i:653;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:19:"typography_fontsize";i:1;a:2:{i:0;i:1;i:1;a:1:{s:12:"declarations";a:1:{s:9:"font-size";s:5:"large";}}}i:2;i:1;i:3;s:10:"<fs large>";}i:2;i:11581;}i:654;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:11591;}i:655;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:"Approffondir :";}i:2;i:11593;}i:656;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:11607;}i:657;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:19:"typography_fontsize";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:5:"</fs>";}i:2;i:11609;}i:658;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:3;i:1;s:266:" Il existe un dernier algorithme qui est utilisé dans le cas de la régression linéaire. Il s'agit de la descente de gradient par lot. Ici on on n'utilise pas une ou toute les valeurs à chaque itération mais un lot. Il n'y a pas de grosses différences notables.";}i:2;i:3;i:3;s:266:" Il existe un dernier algorithme qui est utilisé dans le cas de la régression linéaire. Il s'agit de la descente de gradient par lot. Ici on on n'utilise pas une ou toute les valeurs à chaque itération mais un lot. Il n'y a pas de grosses différences notables.";}i:2;i:11614;}i:659;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:5:"color";i:1;a:2:{i:0;i:4;i:1;s:0:"";}i:2;i:4;i:3;s:8:"</color>";}i:2;i:11880;}i:660;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:11888;}i:661;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:11888;}i:662;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:11890;}i:663;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"Source :";}i:2;i:11892;}i:664;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:11900;}i:665;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:11902;}i:666;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:11902;}i:667;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:11902;}i:668;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:11902;}i:669;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:11906;}i:670;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:83:"http://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/fr_Tanagra_Gradient_Descent_R.pdf";i:1;N;}i:2;i:11907;}i:671;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:11990;}i:672;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:11990;}i:673;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:11990;}i:674;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:11990;}i:675;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:11994;}i:676;a:3:{i:0;s:12:"externallink";i:1;a:2:{i:0;s:99:"http://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/fr_Tanagra_Stochastic_Gradient_Descent_Python.pdf";i:1;N;}i:2;i:11995;}i:677;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:12094;}i:678;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:12094;}i:679;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:12094;}i:680;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:12096;}i:681;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:9:"Synthèse";i:1;i:2;i:2;i:12096;}i:2;i:12096;}i:682;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:12096;}i:683;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:12096;}i:684;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:81:"Rappelons rapidements les différents algorithmes que nous avons dans cette page
";}i:2;i:12117;}i:685;a:3:{i:0;s:9:"linebreak";i:1;a:0:{}i:2;i:12198;}i:686;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:12200;}i:687;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:5;i:1;i:5;i:2;i:12201;}i:2;i:12200;}i:688;a:3:{i:0;s:15:"tablethead_open";i:1;a:0:{}i:2;i:12200;}i:689;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:12200;}i:690;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12200;}i:691;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:"  Algorithme  ";}i:2;i:12202;}i:692;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:12216;}i:693;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12216;}i:694;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"  m grand  ";}i:2;i:12217;}i:695;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:12228;}i:696;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12228;}i:697;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:11:"  n grand  ";}i:2;i:12229;}i:698;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:12240;}i:699;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:5:"right";i:2;i:1;}i:2;i:12240;}i:700;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:24:"  Normalisation requise ";}i:2;i:12241;}i:701;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:12265;}i:702;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:12265;}i:703;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:25:" Hors mémoire possible  ";}i:2;i:12266;}i:704;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:12291;}i:705;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:12292;}i:706;a:3:{i:0;s:16:"tablethead_close";i:1;a:0:{}i:2;i:12292;}i:707;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:12292;}i:708;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12292;}i:709;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"  Equation normale  ";}i:2;i:12294;}i:710;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12314;}i:711;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12314;}i:712;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"  rapide  ";}i:2;i:12315;}i:713;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12325;}i:714;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12325;}i:715;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"  lent  ";}i:2;i:12326;}i:716;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12334;}i:717;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12334;}i:718;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  non  ";}i:2;i:12335;}i:719;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12342;}i:720;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12342;}i:721;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  non  ";}i:2;i:12343;}i:722;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12350;}i:723;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:12351;}i:724;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:12351;}i:725;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12351;}i:726;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:"  Régression linéaire classique  ";}i:2;i:12353;}i:727;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12388;}i:728;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12388;}i:729;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"  rapide  ";}i:2;i:12389;}i:730;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12399;}i:731;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12399;}i:732;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"  lent  ";}i:2;i:12400;}i:733;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12408;}i:734;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12408;}i:735;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  non  ";}i:2;i:12409;}i:736;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12416;}i:737;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12416;}i:738;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  non  ";}i:2;i:12417;}i:739;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12424;}i:740;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:12425;}i:741;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:12425;}i:742;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12425;}i:743;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:"  Descente de gradient classique  ";}i:2;i:12427;}i:744;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12461;}i:745;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12461;}i:746;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:8:"  lent  ";}i:2;i:12462;}i:747;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12470;}i:748;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12470;}i:749;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"  rapide  ";}i:2;i:12471;}i:750;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12481;}i:751;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12481;}i:752;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  oui  ";}i:2;i:12482;}i:753;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12489;}i:754;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12489;}i:755;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  oui  ";}i:2;i:12490;}i:756;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12497;}i:757;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:12498;}i:758;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:12498;}i:759;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12498;}i:760;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:37:"  Descente de gradient stochastique  ";}i:2;i:12500;}i:761;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12537;}i:762;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12537;}i:763;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"  rapide  ";}i:2;i:12538;}i:764;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12548;}i:765;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12548;}i:766;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"  rapide  ";}i:2;i:12549;}i:767;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12559;}i:768;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12559;}i:769;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  oui  ";}i:2;i:12560;}i:770;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12567;}i:771;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:6:"center";i:2;i:1;}i:2;i:12567;}i:772;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:7:"  oui  ";}i:2;i:12568;}i:773;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:12575;}i:774;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:12576;}i:775;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:12576;}i:2;i:12576;}i:776;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:12576;}i:777;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:12576;}}