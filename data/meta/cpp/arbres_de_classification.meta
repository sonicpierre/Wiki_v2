a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1595945865;s:8:"modified";i:1597535198;}s:7:"creator";s:14:"Pierre Virgaux";s:4:"user";s:13:"pierrevirgaux";s:11:"last_change";a:8:{s:4:"date";i:1597535198;s:2:"ip";s:12:"88.124.10.73";s:4:"type";s:1:"E";s:2:"id";s:28:"cpp:arbres_de_classification";s:4:"user";s:13:"pierrevirgaux";s:3:"sum";s:13:"[Conclusion] ";s:5:"extra";s:0:"";s:10:"sizechange";i:42;}s:11:"contributor";a:2:{s:13:"pierrevirgaux";s:14:"Pierre Virgaux";s:6:"julien";s:14:"Buisson-Chavot";}s:8:"relation";a:3:{s:10:"references";a:4:{s:6:"cpp:ia";b:1;s:35:"cpp:autre_algorithme_classification";b:1;s:25:"cpp:regression_supervisee";b:1;s:48:"cpp:les_foret_de_classification_et_de_regression";b:1;}s:5:"media";a:11:{s:13:"cpp:groot.jpg";b:1;s:35:"cpp:arbre_binaire_vulgarisation.png";b:1;s:16:"cpp:impurete.png";b:1;s:21:"cpp:arbredetaille.png";b:1;s:18:"cpp:fonctionx3.png";b:1;s:15:"cpp:treereg.png";b:1;s:24:"cpp:resulatatregtree.png";b:1;s:26:"cpp:sousajustementtree.png";b:1;s:31:"cpp:overfitingsurregression.png";b:1;s:35:"cpp:compareprecisionginientropy.png";b:1;s:30:"cpp:controleoverfitingtree.png";b:1;}s:10:"firstimage";s:13:"cpp:groot.jpg";}s:5:"title";s:23:"Les arbres de décision";s:11:"description";a:2:{s:15:"tableofcontents";a:10:{i:0;a:4:{s:3:"hid";s:22:"les_arbres_de_decision";s:5:"title";s:23:"Les arbres de décision";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:31:"principe_des_arbres_de_decision";s:5:"title";s:32:"Principe des arbres de décision";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:10:"arbre_cart";s:5:"title";s:10:"Arbre CART";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:24:"les_arbres_de_regression";s:5:"title";s:25:"Les arbres de régression";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:4;a:4:{s:3:"hid";s:40:"generer_les_donnees_et_entrainer_l_arbre";s:5:"title";s:44:"Générer les données et entraîner l'arbre";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:5;a:4:{s:3:"hid";s:35:"visualiser_l_arbre_et_la_regression";s:5:"title";s:36:"Visualiser l'arbre et la régression";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:19:"avoir_la_main_verte";s:5:"title";s:19:"Avoir la main verte";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:7;a:4:{s:3:"hid";s:37:"savoir_controler_la_pousse_de_l_arbre";s:5:"title";s:38:"Savoir contrôler la pousse de l'arbre";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:8;a:4:{s:3:"hid";s:34:"evaluations_specifiques_aux_arbres";s:5:"title";s:35:"Evaluations spécifiques aux arbres";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:9;a:4:{s:3:"hid";s:10:"conclusion";s:5:"title";s:10:"Conclusion";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:510:"Machine Learning



Pour faire de la classification, les arbres sont particulièrement sont beaucoup utilisé. Il existe plusieurs types d'arbres pour classifier les données.

Les arbres de décision

Prenons ici l'exemple du Titanic et tentons de prédire quelles seraient vos chance de survie. Vous pouvez récupérer le dataset $$Ent(E) = -\sum_{i=1}^{k} p_{i} * log(p_{i})$$$$Gini(E) = \sum_{i=1}^{k} p_{i} * (1-p_{i})$$$p_{i}$$J(k, t_{k})$$$J(k, t_{k}) = \frac{n_{gauche}}{n}G_{gauche} + \frac{n_{droi…";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1595945865;s:8:"modified";i:1597535198;}s:7:"creator";s:14:"Pierre Virgaux";s:4:"user";s:13:"pierrevirgaux";s:11:"last_change";a:8:{s:4:"date";i:1597535198;s:2:"ip";s:12:"88.124.10.73";s:4:"type";s:1:"E";s:2:"id";s:28:"cpp:arbres_de_classification";s:4:"user";s:13:"pierrevirgaux";s:3:"sum";s:13:"[Conclusion] ";s:5:"extra";s:0:"";s:10:"sizechange";i:42;}s:11:"contributor";a:2:{s:13:"pierrevirgaux";s:14:"Pierre Virgaux";s:6:"julien";s:14:"Buisson-Chavot";}}}