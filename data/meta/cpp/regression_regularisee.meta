a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1593622061;s:8:"modified";i:1606213087;}s:7:"creator";s:14:"Pierre Virgaux";s:4:"user";s:13:"pierrevirgaux";s:11:"last_change";a:8:{s:4:"date";i:1606213087;s:2:"ip";s:12:"88.124.10.73";s:4:"type";s:1:"E";s:2:"id";s:26:"cpp:regression_regularisee";s:4:"user";s:13:"pierrevirgaux";s:3:"sum";s:19:"[Le modèle Ridge] ";s:5:"extra";s:0:"";s:10:"sizechange";i:106;}s:11:"contributor";a:2:{s:13:"pierrevirgaux";s:14:"Pierre Virgaux";s:15:"danilouchouchou";s:6:"Daniel";}s:8:"relation";a:3:{s:10:"references";a:2:{s:6:"cpp:ia";b:1;s:25:"cpp:regression_supervisee";b:1;}s:5:"media";a:13:{s:29:"cpp:regressionpolynomiale.png";b:1;s:37:"cpp:droite_regression_donnee_poly.png";b:1;s:29:"cpp:donnees_mise_au_carre.png";b:1;s:22:"cpp:resultat_coefs.png";b:1;s:22:"cpp:donnee_ajustee.png";b:1;s:20:"cpp:underfitting.png";b:1;s:29:"cpp:overfittingpolynomial.png";b:1;s:16:"cpp:shinkage.png";b:1;s:22:"cpp:resultat_ridge.png";b:1;s:13:"cpp:lasso.png";b:1;s:26:"cpp:selected_variables.png";b:1;s:25:"cpp:selected_features.png";b:1;s:29:"cpp:elasticnet_evaluation.png";b:1;}s:10:"firstimage";s:29:"cpp:regressionpolynomiale.png";}s:5:"title";s:26:"La régression polynomiale";s:11:"description";a:2:{s:15:"tableofcontents";a:9:{i:0;a:4:{s:3:"hid";s:25:"la_regression_polynomiale";s:5:"title";s:26:"La régression polynomiale";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:1;a:4:{s:3:"hid";s:31:"generer_les_points_de_l_exemple";s:5:"title";s:33:"Générer les points de l'exemple";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:2;a:4:{s:3:"hid";s:30:"creer_les_donnees_polynomiales";s:5:"title";s:32:"Créer les données polynomiales";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:3;a:4:{s:3:"hid";s:22:"entrainement_du_modele";s:5:"title";s:23:"Entrainement du modèle";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:4;a:4:{s:3:"hid";s:23:"les_modeles_regularises";s:5:"title";s:26:"Les modèles régularisés";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:5;a:4:{s:3:"hid";s:15:"le_modele_ridge";s:5:"title";s:16:"Le modèle Ridge";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:6;a:4:{s:3:"hid";s:15:"le_modele_lasso";s:5:"title";s:16:"Le modèle Lasso";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:7;a:4:{s:3:"hid";s:21:"le_modele_elastic_net";s:5:"title";s:22:"Le modèle Elastic net";s:4:"type";s:2:"ul";s:5:"level";i:3;}i:8;a:4:{s:3:"hid";s:14:"lequel_choisir";s:5:"title";s:16:"Lequel choisir ?";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:512:"Machine Learning



La régression polynomiale

Les données ne sont pas toujours modélisables par une droite, ce qui nécessite l'utilisation de fonctions polynomiales qui permettent de faire de meilleures prédictions.

Générer les points de l'exemple

Comme pour la page sur la $J(\Theta)$$$
J(\Theta) = \underbrace{MSE(\Theta)}_{\text{Fonction coût}}  + \underbrace{\alpha \frac{1}{2} \sum_{i = 1}^{n} \Theta_{i}^{2}}_{\text{Terme de régularisation}}
$$$\alpha$$\Theta$$\alpha$$\alpha$$l_{2}$$l_{1}$$…";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1593622061;s:8:"modified";i:1606213087;}s:7:"creator";s:14:"Pierre Virgaux";s:4:"user";s:13:"pierrevirgaux";s:11:"last_change";a:8:{s:4:"date";i:1606213087;s:2:"ip";s:12:"88.124.10.73";s:4:"type";s:1:"E";s:2:"id";s:26:"cpp:regression_regularisee";s:4:"user";s:13:"pierrevirgaux";s:3:"sum";s:19:"[Le modèle Ridge] ";s:5:"extra";s:0:"";s:10:"sizechange";i:106;}s:11:"contributor";a:2:{s:13:"pierrevirgaux";s:14:"Pierre Virgaux";s:15:"danilouchouchou";s:6:"Daniel";}}}